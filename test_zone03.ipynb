{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from utility import *\n",
    "from box_utils import *\n",
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_torch(boxes, scores, overlap=0.5, top_k=200):\n",
    "    \"\"\"Apply non-maximum suppression at test time to avoid detecting too many\n",
    "    overlapping bounding boxes for a given object.\n",
    "    Args:\n",
    "        boxes: (tensor) The location preds for the img, Shape: [num_priors,4].\n",
    "        scores: (tensor) The class predscores for the img, Shape:[num_priors].\n",
    "        overlap: (float) The overlap thresh for suppressing unnecessary boxes.\n",
    "        top_k: (int) The Maximum number of box preds to consider.\n",
    "    Return:\n",
    "        The indices of the kept boxes with respect to num_priors.\n",
    "    \"\"\"\n",
    "\n",
    "    keep = scores.new(scores.size(0)).zero_().long()\n",
    "    if boxes.numel() == 0:\n",
    "        return keep\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    area = torch.mul(x2 - x1, y2 - y1)\n",
    "    v, idx = scores.sort(0)  # sort in ascending order\n",
    "    # I = I[v >= 0.01]\n",
    "    idx = idx[-top_k:]  # indices of the top-k largest vals\n",
    "    xx1 = boxes.new()\n",
    "    yy1 = boxes.new()\n",
    "    xx2 = boxes.new()\n",
    "    yy2 = boxes.new()\n",
    "    w = boxes.new()\n",
    "    h = boxes.new()\n",
    "\n",
    "    # keep = torch.Tensor()\n",
    "    count = 0\n",
    "    while idx.numel() > 0:\n",
    "        i = idx[-1]  # index of current largest val\n",
    "        # keep.append(i)\n",
    "        keep[count] = i\n",
    "        count += 1\n",
    "        if idx.size(0) == 1:\n",
    "            break\n",
    "        idx = idx[:-1]  # remove kept element from view\n",
    "        # load bboxes of next highest vals\n",
    "        torch.index_select(x1, 0, idx, out=xx1)\n",
    "        torch.index_select(y1, 0, idx, out=yy1)\n",
    "        torch.index_select(x2, 0, idx, out=xx2)\n",
    "        torch.index_select(y2, 0, idx, out=yy2)\n",
    "        # store element-wise max with next highest score\n",
    "        xx1 = torch.clamp(xx1, min=x1[i])\n",
    "        yy1 = torch.clamp(yy1, min=y1[i])\n",
    "        xx2 = torch.clamp(xx2, max=x2[i])\n",
    "        yy2 = torch.clamp(yy2, max=y2[i])\n",
    "        w.resize_as_(xx2)\n",
    "        h.resize_as_(yy2)\n",
    "        w = xx2 - xx1\n",
    "        h = yy2 - yy1\n",
    "        # check sizes of xx1 and xx2.. after each iteration\n",
    "        w = torch.clamp(w, min=0.0)\n",
    "        h = torch.clamp(h, min=0.0)\n",
    "        inter = w*h\n",
    "        # IoU = i / (area(a) + area(b) - i)\n",
    "        rem_areas = torch.index_select(area, 0, idx)  # load remaining areas)\n",
    "        union = (rem_areas - inter) + area[i]\n",
    "        IoU = inter/union  # store result in iou\n",
    "        # keep only elements with an IoU <= overlap\n",
    "        idx = idx[IoU.le(overlap)]\n",
    "\n",
    "    return keep, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detect(Function):\n",
    "    \"\"\"At test time, Detect is the final layer of SSD.  Decode location preds,\n",
    "    apply non-maximum suppression to location predictions based on conf\n",
    "    scores and threshold to a top_k number of output predictions for both\n",
    "    confidence score and locations.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, bkg_label, top_k, conf_thresh, nms_thresh):\n",
    "        self.num_classes = num_classes\n",
    "        self.background_label = bkg_label\n",
    "        self.top_k = top_k\n",
    "        # Parameters used in nms.\n",
    "        self.nms_thresh = nms_thresh\n",
    "        if nms_thresh <= 0:\n",
    "            raise ValueError('nms_threshold must be non negative.')\n",
    "        self.conf_thresh = conf_thresh\n",
    "        self.variance = [0.1, 0.2]\n",
    "\n",
    "    def forward(self, loc_data, conf_data, prior_data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            loc_data: (tensor) Loc preds from loc layers\n",
    "                Shape: [batch,num_priors*4]\n",
    "            conf_data: (tensor) Shape: Conf preds from conf layers\n",
    "                Shape: [batch*num_priors,num_classes]\n",
    "            prior_data: (tensor) Prior boxes and variances from priorbox layers\n",
    "                Shape: [1,num_priors,4]\n",
    "        \"\"\"\n",
    "        num = loc_data.size(0)  # batch size\n",
    "        num_priors = prior_data.size(0)\n",
    "        \n",
    "        output = torch.zeros(num, self.num_classes, self.top_k, 5)\n",
    "        \n",
    "        conf_preds = conf_data.view(num, num_priors,\n",
    "                                    self.num_classes).transpose(2, 1)\n",
    "\n",
    "        # Decode predictions into bboxes.\n",
    "        for i in range(num):\n",
    "            decoded_boxes = decode(loc_data[i], prior_data, self.variance)\n",
    "            print(decoded_boxes.size())\n",
    "            # For each class, perform nms\n",
    "            conf_scores = conf_preds[i].clone()\n",
    "\n",
    "            for cl in range(1, self.num_classes):\n",
    "                c_mask = conf_scores[cl].gt(self.conf_thresh)\n",
    "#                 print(c_mask.size())\n",
    "                scores = conf_scores[cl][c_mask]\n",
    "                if scores.size(0) == 0:\n",
    "                    continue\n",
    "                l_mask = c_mask.unsqueeze(1).expand_as(decoded_boxes)\n",
    "#                 print(l_mask.size())\n",
    "                boxes = decoded_boxes[l_mask].view(-1, 4)\n",
    "                # idx of highest scoring and non-overlapping boxes per class\n",
    "                ids, count = nms(boxes, scores, self.nms_thresh, self.top_k)\n",
    "#                 output[i, cl, :count] = \\\n",
    "#                     torch.cat((scores[ids[:count]].unsqueeze(1),\n",
    "#                                boxes[ids[:count]]), 1)\n",
    "#         flt = output.contiguous().view(num, -1, 5)\n",
    "#         _, idx = flt[:, :, 0].sort(1, descending=True)\n",
    "#         _, rank = idx.sort(1)\n",
    "#         flt[(rank < self.top_k).unsqueeze(-1).expand_as(flt)].fill_(0)\n",
    "        return ids, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_np(boxes, scores, overlap = 0.5, top_k= 200):\n",
    "    \n",
    "\n",
    "    keep = np.zeros(shape = scores.shape[0], dtype = np.float32)\n",
    "    \n",
    "    if len(boxes) == 0:\n",
    "        return keep\n",
    "    \n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    \n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    \n",
    "    area = (x2 - x1) * (y2 - y1)\n",
    "    \n",
    "    idx = np.argsort(scores)\n",
    "    \n",
    "    idx = idx[-top_k:]\n",
    "    \n",
    "\n",
    "    \n",
    "    count = 0 \n",
    "    \n",
    "    while len(idx) > 0:\n",
    "        i = idx[-1]  # index of current largest val\n",
    "        \n",
    "        keep[count] = i\n",
    "        count += 1\n",
    "        \n",
    "        if idx.shape[0] == 1:\n",
    "            break\n",
    "            \n",
    "        idx = idx[:-1]\n",
    "        \n",
    "        xx1 = np.take(x1, indices=idx, axis=0)\n",
    "        yy1 = np.take(y1, indices=idx, axis=0)\n",
    "        xx2 = np.take(x2, indices=idx, axis=0)\n",
    "        yy2 = np.take(y2, indices=idx, axis=0)\n",
    "        \n",
    "        xx1 = np.clip(xx1, a_min = x1[i],  a_max=None)\n",
    "        yy1 = np.clip(yy1, a_min = y1[i],  a_max=None)\n",
    "        xx2 = np.clip(xx2, a_min = None,   a_max=x2[i])\n",
    "        yy2 = np.clip(yy2, a_min = None,   a_max=x2[i])\n",
    "        \n",
    "        w = xx2 - xx1\n",
    "        h = yy2 - yy1\n",
    "\n",
    "        \n",
    "        w = np.clip(w, a_min = 0., a_max = None)\n",
    "        h = np.clip(h, a_min = 0., a_max = None)\n",
    "        \n",
    "        inter = w * h\n",
    "        rem_areas = np.take(area, indices = idx, axis = 0) # load remaining areas\n",
    "        union     = (rem_areas - inter) + area[i]\n",
    "        IOU       = inter/union\n",
    "        idx       = idx[np.less_equal(IOU, overlap)]\n",
    "#         print(idx.shape)\n",
    "    return keep, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.random.randn(8732)\n",
    "boxes = np.random.randn(8732, 4)\n",
    "scores = torch.Tensor(score)\n",
    "boxes_ = torch.Tensor(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5819., 5454., 4754., ...,    0.,    0.,    0.], dtype=float32), 182)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nms_np(boxes=boxes, scores=score, overlap=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5819, 5454, 4754,  ...,    0,    0,    0]), 198)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nms_torch(boxes=boxes_, scores=scores, overlap=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detect_np(object):\n",
    "    def __init__(self, \n",
    "                 num_classes   = 21, \n",
    "                 bkg_label   = None, \n",
    "                 conf_thresh = 0.6, \n",
    "                 nms_thresh  = 0.6, \n",
    "                 top_k       = 200,\n",
    "                 variances   = [0.1, 0.2]):\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.bkg_label   = bkg_label\n",
    "        self.conf_thresh = conf_thresh\n",
    "        self.nms_thresh  = nms_thresh\n",
    "        self.top_k       = top_k\n",
    "        self.variances    = variances\n",
    "    \n",
    "    def forward(self, loc_data, conf_data, priors):\n",
    "        \n",
    "#         loc_data   = prediction[:,:,:4]\n",
    "#         conf_data  = prediction[:,:,4:]\n",
    "        \n",
    "        num_priors = priors.shape[0]\n",
    "        batch_size = loc_data.shape[0]\n",
    "        \n",
    "        output  = np.zeros(shape=(batch_size, self.num_classes, self.top_k, 5), dtype= np.float32)\n",
    "        \n",
    "        conf_preds = conf_data.swapaxes(2,1)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            decoded_boxes = decode_np(loc    = loc_data[i], \n",
    "                                      priors = priors,\n",
    "                                      variances=self.variances)\n",
    "            \n",
    "            conf_scores = conf_pred[i].copy()\n",
    "            \n",
    "            for cl in range(1, self.num_classes):\n",
    "                c_mask = np.greater(conf_scores[cl], self.conf_thresh)\n",
    "                scores = conf_scores[cl][c_mask]\n",
    "                \n",
    "                if scores.shape[0] == 0:\n",
    "                    continue\n",
    "                \n",
    "                l_mask =  c_mask.reshape(-1,1).repeat(4, axis= -1)   \n",
    "                boxes  =  decoded_boxes[l_mask].reshape(-1,4) \n",
    "#                 print(boxes.shape)\n",
    "                \n",
    "                ids, count = non_maximum_supression(boxes    =  boxes,\n",
    "                                                    scores   = scores, \n",
    "                                                    overlap  =  self.nms_thresh,\n",
    "                                                    top_k    = self.top_k)\n",
    "                \n",
    "#                 print(ids.shape)\n",
    "#                 print(count)\n",
    "                \n",
    "                \n",
    "#                 output[i, cl, :count] = np.concatenate((temp.reshape(-1,1), \n",
    "#                                                         boxes[ids[:count]]), axis=-1)\n",
    "                \n",
    "#         flt = output.ascontiguousarray().reshape(batch_size, -1, 5)\n",
    "#         idx  = np.argsort(flt[:,:,0], axis=-1)\n",
    "#         rank = np.argsort(idx, axis=-1)\n",
    "        \n",
    "#         flt[rank < self.top_k].ex\n",
    "        return ids, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_data = np.random.randn(4, 8732, 4)\n",
    "loc_data_th = torch.Tensor(loc_data).view(4, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors    = np.random.randn(8732, 4)\n",
    "priors_th = torch.Tensor(priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8732, 21)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_data = np.random.randn(4, 8732, 21)\n",
    "conf_data_th = torch.Tensor(conf_data).view(-1, 21)\n",
    "conf_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 21, 8732)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_pred = conf_data.swapaxes(2,1)\n",
    "conf_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "aa = torch.Tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = aa.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-08e1e2cdda1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhello\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbkg_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconf_thresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnms_thresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhello\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloc_data_th\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf_data_th\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpriors_th\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-dc6e597c7da4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, loc_data, conf_data, prior_data)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Decode predictions into bboxes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mdecoded_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_boxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# For each class, perform nms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python_codes/keras/object_detection/from_gitHUb/ssd.pytorch/box_utils.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(loc, priors, variances)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     boxes = torch.cat((\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mpriors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvariances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpriors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         priors[:, 2:] * torch.exp(loc[:, 2:] * variances[1])), 1)\n\u001b[1;32m    158\u001b[0m     \u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "\n",
    "hello = Detect(num_classes=21, bkg_label=None,conf_thresh=0.5, nms_thresh=0.6, top_k=200)\n",
    "\n",
    "test = hello.forward(loc_data=loc_data_th, conf_data=conf_data_th, prior_data=priors_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, count = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello2 = Detect_np(num_classes   = 21, \n",
    "                 bkg_label   = None, \n",
    "                 conf_thresh = 0.6, \n",
    "                 nms_thresh  = 0.6, \n",
    "                 top_k       = 200,\n",
    "                 variances   = [0.1, 0.2])\n",
    "\n",
    "test2 = hello2.forward(loc_data= loc_data, conf_data = conf_data, priors= priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_, count_ = test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_[:count_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids[:count]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
